---
title: "Assignment"
description: |
  This assignment is aim to solve the problems of for Mini Challenge 2
author:
  - name: LI NAN
    url: https://www.linkedin.com/in/li-nan-63b9251a6/
date: 07-12-2021
output:
  distill::distill_article:
    toc: true
    toc_depth: 3



---

## 1.Data Preparation

### 1.1 Global Settings

The global settings of R code chunks in this post is set as follows. 

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(fig.retina = 3,
                      echo = TRUE,
                      eval = TRUE,
                      message = FALSE,
                      warning = FALSE)
```

### 1.2 R Packages Installation

The following code input is to prepare for R Packages Installation.

```{r}
packages = c('DT', 'ggiraph', 'plotly', 'tidyverse','dplyr','readr','hrbrthemes')
for(p in packages){
  if(!require(p, character.only = T)){
    install.packages(p)
  }
  library(p, character.only = T)
}

```

### 1.3 Data Import
The following code is to import raw data sets from [<font size="3"  color="blue">*Mini Challenge2*</font>](https://vast-challenge.github.io/2021/MC2.html)("*car-assignment.csv*","*cc_data.csv*","*gps.csv*","*loyalty_data.csv*").

```{r}
credit_debit <- read_csv("data/cc_data.csv")
loyalty_data <- read_csv("data/loyalty_data.csv")
car_assignment <- read_csv("data/car_assignments.csv")
GPS <- read_csv("data/gps.csv")
glimpse(credit_debit)
glimpse(loyalty_data)
head(loyalty_data)
head(credit_debit)
```
## 2.Tasks and Questions for Mini-Challenge2

### 2.1 Q1 Intruoduction

Using just the credit and loyalty card data, identify the most popular locations, and when they are popular. What anomalies do you see? What corrections would you recommend to correct these anomalies?


### 2.2 Data Preparation for Q1


After glimpsing data structure of credit and loyalty card data, the heat map is a good way to visualize the most population locations and its population time.To create this graph,the data aggregation of loyalty card is needed.

```{r}
loyalty_data$count_event=1
credit_debit$count_event=1

aggregate_dataset <- loyalty_data %>% 
    group_by(timestamp,location) %>% 
    summarize(Frequency = sum(count_event))
head(aggregate_dataset)

credit_debit$timestamp <- as.Date(credit_debit$timestamp, "%m/%d/%Y")
aggregate_cc <- credit_debit %>% 
    group_by(timestamp,location) %>% 
    summarize(Frequency = sum(count_event))
head(aggregate_cc)


```
**Adjustment of Date Type and create a new column named"Day"**
```{r}
aggregate_dataset$timestamp <- as.Date(aggregate_dataset$timestamp, "%m/%d/%Y")

aggregate_dataset$Day <- format(aggregate_dataset$timestamp, format="%d")
aggregate_cc$Day <- format(aggregate_cc$timestamp, format="%d")
head(aggregate_dataset)
head(aggregate_cc)
```
**new column: text for tooltip**
```{r}
aggregate_dataset <- aggregate_dataset %>%
  mutate(text = paste0("Location: ", location, "\n", "Day of January: ", Day, "\n", "Frequency: ",Frequency))

aggregate_cc <- aggregate_cc %>%
  mutate(text2 = paste0("Location: ", location, "\n", "Day of January: ", Day, "\n", "Frequency: ",Frequency))
```


**Heat map for loyalty card**
```{r,fig.height=6,fig.width=10}
p <- ggplot(data = aggregate_dataset, aes(x=Day, y=location,fill=Frequency,text=text)) + 
  geom_tile() +
  scale_fill_gradient(low="light blue", high="dark blue") +
  theme_ipsum()

p <- p + theme(axis.text.y = element_text(size = 8))

ggplotly(p, tooltip="text")
```

**Heat map for credit_debit card**
```{r,fig.height=6,fig.width=10}
z <- ggplot(data = aggregate_cc, aes(x=Day, y=location,fill=Frequency,text=text2)) + 
  geom_tile() +
  scale_fill_gradient(low="light yellow", high="red") +
  theme_ipsum()

z <- z + theme(axis.text.y = element_text(size = 8))

ggplotly(z, tooltip="text2")
```


The following tables also show the result of the most popular location in each day of Jan-2014 based on loyalty data and credit_debit data.From the data tables,we can know that Brew've Been Served and Katerina's Cafe appear frequently in this table,showing that they are the most popular places based on loyalyty data.


```{r}

aggregate_dataset %>% group_by(Day) %>% slice(which.max(Frequency))
```

```{r}

aggregate_cc %>% group_by(Day) %>% slice(which.max(Frequency))
```
